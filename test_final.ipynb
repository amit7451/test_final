{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m0gJNAw2HJ81"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Tree / Boosting models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = '/kaggle/input/mock-test-2-mse-2/train.csv'\n",
        "TEST_PATH  = '/kaggle/input/mock-test-2-mse-2/test.csv'\n",
        "TARGET_COL = 'Status'\n",
        "ID_COL     = 'id'\n",
        "\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df  = pd.read_csv(TEST_PATH)"
      ],
      "metadata": {
        "id": "EPa2koOeHfzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "KJO-ybOdHyBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "GAVcGUjlH2fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "LCDEbODfH5Fy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(train_df[TARGET_COL])\n",
        "\n",
        "X = train_df.drop(columns=[TARGET_COL])\n",
        "X_test = test_df.copy()"
      ],
      "metadata": {
        "id": "q27vQJYKH-IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X.select_dtypes(include=['int64','float64']).columns\n",
        "cat_cols = X.select_dtypes(exclude=['int64','float64']).columns\n"
      ],
      "metadata": {
        "id": "xL0uWjtJIIH-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_cols),\n",
        "        ('cat', categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "kdyF7a7RIR0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cap_outliers(df, cols, lower=1, upper=99):\n",
        "    \"\"\"Caps outliers using percentile-based winsorization.\"\"\"\n",
        "    df = df.copy()\n",
        "    for c in cols:\n",
        "        lo, hi = df[c].quantile([lower/100, upper/100])\n",
        "        df[c] = df[c].clip(lo, hi)\n",
        "    return df\n",
        "\n",
        "# ---- APPLY OUTLIER CAPPING (ALWAYS) ----\n",
        "train_df[num_cols] = cap_outliers(train_df, num_cols)\n",
        "test_df[num_cols]  = cap_outliers(test_df, num_cols)\n",
        "\n",
        "# Re-create X and X_test after capping\n",
        "X = train_df.drop(columns=[TARGET_COL])\n",
        "X_test = test_df.copy()"
      ],
      "metadata": {
        "id": "oQv2hivMTaZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_cols[:6]:  # limit to first 6 to avoid clutter\n",
        "    plt.figure(figsize=(5, 2))\n",
        "    sns.boxplot(x=train_df[col])\n",
        "    plt.title(f\"Boxplot: {col}\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYT16l6tTkp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(num_cols) > 1:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    corr = train_df[num_cols].corr()\n",
        "    sns.heatmap(corr, cmap='coolwarm', center=0)\n",
        "    plt.title(\"Correlation Matrix (Numerical Features)\")\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "bQkeVh29TlVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(num_cols) <= 5:\n",
        "    sns.pairplot(train_df[num_cols.tolist() + [TARGET_COL]], hue=TARGET_COL)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "VVH9mARUTpdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=None,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    'LightGBM': lgb.LGBMClassifier(\n",
        "        objective='multiclass',\n",
        "        n_estimators=700,\n",
        "        learning_rate=0.03,\n",
        "        num_leaves=31,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    'XGBoost': xgb.XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        eval_metric='mlogloss',\n",
        "        n_estimators=700,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        tree_method='hist',\n",
        "        random_state=42\n",
        "    )\n",
        "}\n"
      ],
      "metadata": {
        "id": "9u2YCM_UIWKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "from sklearn.base import clone\n",
        "\n",
        "for name, model in models.items():\n",
        "    losses = []\n",
        "    for train_idx, val_idx in skf.split(X, y):\n",
        "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        # IMPORTANT: clone model for each fold (fixes LightGBM/XGBoost feature mismatch)\n",
        "        model_clone = clone(model)\n",
        "\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('model', model_clone)\n",
        "        ])\n",
        "\n",
        "        pipe.fit(X_tr, y_tr)\n",
        "        val_pred = pipe.predict_proba(X_val)\n",
        "        losses.append(log_loss(y_val, val_pred))\n",
        "\n",
        "    results[name] = np.mean(losses)\n",
        "    print(f\"{name} CV LogLoss: {results[name]:.5f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yF7L7v5CMK8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = min(results, key=results.get)\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "print(f\"\\nBest Model Selected: {best_model_name}\")"
      ],
      "metadata": {
        "id": "W4So4eXJMS-n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CALIBRATION_FOR_LOGLOSS = True  # True for LogLoss, False for Accuracy/F1\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "if USE_CALIBRATION_FOR_LOGLOSS:\n",
        "    calibrated_model = CalibratedClassifierCV(\n",
        "        estimator=best_model,\n",
        "        method='isotonic',\n",
        "        cv=3\n",
        "    )\n",
        "\n",
        "    final_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', calibrated_model)\n",
        "    ])\n",
        "else:\n",
        "    final_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', best_model)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "sE2WSi9HQQpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipeline.fit(X, y)"
      ],
      "metadata": {
        "id": "SWOQ9GIDMWHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUBMIT_PROBABILITIES = True   # True → log_loss submission\n",
        "SUBMIT_LABELS        = False  # True → accuracy / precision submission\n"
      ],
      "metadata": {
        "id": "kso5_L2_SErJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_labels_enc = final_pipeline.predict(X_test)\n",
        "y_pred_prob = final_pipeline.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "gbXBibBaSKh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if SUBMIT_PROBABILITIES:\n",
        "    # Get class labels exactly as model sees them\n",
        "    class_labels = final_pipeline.named_steps['model'].classes_\n",
        "\n",
        "    submission_cols = [f\"{TARGET_COL}_{label}\" for label in class_labels]\n",
        "\n",
        "    submission = pd.DataFrame(y_pred_prob, columns=submission_cols)\n",
        "    submission.insert(0, ID_COL, test_df[ID_COL])\n",
        "\n",
        "    # OPTIONAL: rename / reorder if professor requires specific names\n",
        "    # Example mapping (EDIT AFTER SEEING sampleSubmission.csv)\n",
        "    # submission = submission.rename(columns={\n",
        "    #     'Status_0': 'Status_D',\n",
        "    #     'Status_1': 'Status_C',\n",
        "    #     'Status_2': 'Status_CL'\n",
        "    # })\n",
        "\n",
        "    # Example reorder\n",
        "    # submission = submission[['id', 'Status_C', 'Status_CL', 'Status_D']]\n",
        "\n",
        "    submission.to_csv('Submission.csv', index=False)\n",
        "    print('Submission.csv generated (probabilities)')"
      ],
      "metadata": {
        "id": "KKYUr3J2QPUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SUBMIT_LABELS:\n",
        "    # • For accuracy / precision → use model.predict()\n",
        "\n",
        "    y_pred_labels = label_encoder.inverse_transform(y_pred_labels_enc)\n",
        "\n",
        "    labels_df = pd.DataFrame({\n",
        "        ID_COL: test_df[ID_COL],\n",
        "        f'{TARGET_COL}_pred': y_pred_labels\n",
        "    })\n",
        "\n",
        "    labels_df.to_csv('Submission_labels.csv', index=False)\n",
        "    print('Submission_labels.csv generated (labels)')"
      ],
      "metadata": {
        "id": "SsqcS5gpPICO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}